import argparse
import json
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os
import seaborn as sns

from collections import defaultdict, Counter
from constants import (
    PATH_EVALUATION,
    FILE_RESULTS,
    FOLDER_FIGURES,
    FOLDER_TRAJS,
)
from glob import glob
from itertools import islice


VALID_ACTIONS = [
    'search_dir', 'find_file', 'create', 'edit', 'search_dir',
    'search_file', 'goto', 'submit', 'exit_cost', 'open',
    'scroll_up', 'scroll_down', 'python', 'pytest', '<START>', '<END>'
]


def get_list_of_actions(traj):
    """
    Get list of actions from a trajectory
    """
    return [t['action'].split()[0] for t in 
        [{'action': '<START> x'}] + \
        traj['trajectory'] + \
        [{'action': '<END> x'}]
   ]

def find_ngrams(sequence, n):
    """
    Find all n-grams in a sequence of actions
    """
    return zip(*(islice(sequence, i, None) for i in range(n)))


def transition_probs(model, split, n, n_most_common, resolved):
    path_result = os.path.join(PATH_EVALUATION, split, model, FILE_RESULTS)
    path_trajs  = os.path.join(PATH_EVALUATION, split, model, FOLDER_TRAJS)

    if not os.path.exists(path_result):
        raise FileNotFoundError(f"Results not found at {path_result} (Run resolved.by_count first first)")
    if not os.path.exists(path_trajs):
        raise FileNotFoundError(f"`traj/` folder containing .traj data not found at {path_trajs}")

    # Load results
    results = json.load(open(path_result))

    # Get list of actions for each trajectory
    data = []
    for traj_path in glob(os.path.join(path_trajs, "*.traj")):
        inst_id = traj_path.split("/")[-1].split(".")[0]
        if resolved and inst_id not in results['resolved']:
            continue
        traj = json.load(open(traj_path))
        data.append(get_list_of_actions(traj))
    
    # Flatten the list of lists
    flattened_data = [action for sequence in data for action in sequence]

    # Find all n-grams
    ngrams = find_ngrams(flattened_data, n)

    # Count the frequency of each n-gram
    ngram_counts = Counter(ngrams)

    # Count the frequency of each transition
    transitions = defaultdict(Counter)
    most_common = [
        ", ".join(x[0])
        for x in ngram_counts.most_common(n_most_common)
    ]

    # Count the frequency of each transition
    for sequence in data:
        for i in range(len(sequence) - n):
            lead_up = ", ".join(sequence[i:i+n])
            if n == 1 and sequence[i] not in VALID_ACTIONS:
                # Skip if the action is not valid
                continue
            if n > 1 and lead_up not in most_common:
                # Skip if the n-gram is not in the most common
                continue
            if sequence[i+n] not in VALID_ACTIONS:
                # Skip if the next action is not valid
                continue
            transitions[lead_up][sequence[i+n]] += 1
    transition_probs = {k: {kk: vv / sum(v.values()) for kk, vv in v.items()} for k, v in transitions.items()}

    # Shorten keys corresponding to consecutive actions
    to_swap_keys = []
    for k, v in transition_probs.items():
        actions = [x.strip(",") for x in k.split()]
        
        new_key = ""
        count = 0
        prev_action = None
        for action in actions:
            if prev_action == None:
                prev_action = action
                continue
            if prev_action == action:
                count += 1
                continue
            if count >= 1:
                new_key += f"{prev_action} ({count + 1}x), "
            else:
                new_key += f"{prev_action}, "
            prev_action = action
            count = 0

        if count >= 1:
            new_key += f"{prev_action} ({count + 1}x)"
        else:
            new_key += f"{prev_action}"

        if new_key != k:
            to_swap_keys.append((new_key, k))

    for temp in to_swap_keys:
        transition_probs[temp[0]] = transition_probs.pop(temp[1])

    # Create a DataFrame for transition probabilities
    transition_probs_keys = sorted(list(transition_probs.keys()))
    actions = sorted(list(set([x for v in transitions.values() for x in list(v.keys())])))
    transition_matrix = pd.DataFrame(
        np.zeros((len(transition_probs_keys), len(actions))),
        index=transition_probs_keys,
        columns=actions
    )

    for action_ngram, probs in transition_probs.items():
        for next_action, prob in probs.items():
            transition_matrix.at[action_ngram, next_action] = prob
    transition_matrix = transition_matrix.fillna(0.0)

    # Plot the heatmap
    plt.figure(figsize=(12, 8))
    ax = sns.heatmap(transition_matrix, annot=True, cmap='Blues', fmt='.2f', annot_kws={'size': 15})
    plt.title(f'Transition Probabilities Heatmap', fontsize=25)
    plt.xlabel('Next Action', fontsize=22)
    plt.ylabel(f'Previous {n} Actions', fontsize=22)
    plt.xticks(rotation=60, fontsize=20)
    plt.yticks(fontsize=20)

    # Add count of transitions to the right
    ax2 = ax.twinx()
    ax2.set_ylim(ax.get_ylim())
    ax2.set_yticks(ax.get_yticks())
    ax2.set_yticklabels([f"{count}" for count in [
        sum(v.values())
        for k, v in transitions.items()
    ]], fontsize=16)

    # Add colorbar
    colorbar = ax.collections[0].colorbar
    colorbar.ax.tick_params(labelsize=20)
    colorbar.ax.set_position([0.81, 0.15, 0.05, 0.7])
    save_path = os.path.join(
        PATH_EVALUATION, split, model,
        FOLDER_FIGURES, f'transition_probs_{n}gram.pdf'
    )
    if resolved:
        save_path = save_path.replace(".pdf", "_resolved.pdf")
    plt.savefig(save_path, bbox_inches='tight')
    print(f"Results saved to {save_path}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True, help="Name of folder containing model evaluation results (e.g. '20240402_sweagent_gpt4)")
    parser.add_argument("--split", type=str, required=True, help="Name of split to get evaluation results for (should be parent folder, e.g. 'test', 'lite')", choices=["test", "lite"])
    parser.add_argument("--n", type=int, default=2, help="Length of previous action sequence to consider")
    parser.add_argument("--n_most_common", type=int, default=10, help="Number of most common n-grams to consider")
    parser.add_argument("--resolved", action="store_true", help="Only consider resolved instances")
    args = parser.parse_args()
    transition_probs(**vars(args))