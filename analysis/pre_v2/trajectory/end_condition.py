import argparse
import json
import os

from constants import (
    FILE_RESULTS,
    FILE_RESULTS_END_CONDITION,
    FOLDER_TRAJS,
    PATH_EVALUATION,
)
from collections import Counter
from glob import glob

def end_condition(model, split, save_results, resolved):
    split_model_folder = os.path.join(PATH_EVALUATION, split, model)

    # Load model results
    path_result = os.path.join(split_model_folder, FILE_RESULTS)
    if not os.path.exists(path_result):
        raise FileNotFoundError(f"Results not found at {path_result} (Run resolved.by_count first first)")
    results = json.load(open(path_result, "r"))

    # Load model results
    trajs_folder = os.path.join(split_model_folder, FOLDER_TRAJS, "*.traj")
    exit_dist = Counter([
        json.load(open(traj_path))['info']['exit_status']
        for traj_path in glob(trajs_folder)
        if "exit_status" in json.load(open(traj_path))['info'] and
        (not resolved or traj_path.split('/')[-1].split('.')[0] in results['resolved'])
    ])
    print(dict(exit_dist))

    if save_results:
        save_path = os.path.join(split_model_folder, FILE_RESULTS_END_CONDITION)
        if resolved:
            save_path = save_path.replace(".json", "_resolved.json")
        with open(save_path, "w") as f:
            json.dump(dict(exit_dist), fp=f, indent=2)
        print(f"Results saved to {save_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True, help="Name of folder containing model evaluation results (e.g. '20240402_sweagent_gpt4)")
    parser.add_argument("--split", type=str, required=True, help="Name of split to get evaluation results for (should be parent folder, e.g. 'test', 'lite')", choices=["test", "lite"])
    parser.add_argument("--save_results", action="store_true", help="Save results to file")
    parser.add_argument("--resolved", action="store_true", help="Calculate only for resolved tasks")
    args = parser.parse_args()
    end_condition(**vars(args))